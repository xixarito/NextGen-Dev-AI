{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea4eedc",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (3.0.1)\n",
      "Requirement already satisfied: langchain in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: tiktoken in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: chromadb in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: openai in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (1.108.0)\n",
      "Requirement already satisfied: pytest in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (8.4.2)\n",
      "Requirement already satisfied: pytest-mock in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (3.15.1)\n",
      "Requirement already satisfied: pydantic in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (2.11.9)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (0.4.28)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pydantic) (0.4.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from tiktoken) (2025.9.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (2.3.3)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.37.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (1.75.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (0.17.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
      "Requirement already satisfied: iniconfig>=1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pytest) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from pytest) (2.19.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.1)\n",
      "Requirement already satisfied: sympy in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.34.5)\n",
      "Requirement already satisfied: filelock in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install PyPDF2 langchain tiktoken chromadb openai pytest pytest-mock pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e19bdb",
   "metadata": {},
   "source": [
    "## 1. Extracting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c51044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length: 249017\n"
     ]
    }
   ],
   "source": [
    "# pdf_loader.py\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrae todo el texto de un archivo PDF.\n",
    "    Args:\n",
    "      pdf_path (str): Ruta al archivo PDF.\n",
    "    Returns:\n",
    "      str: Texto completo extraído.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = []\n",
    "    for page in reader.pages:\n",
    "        full_text.append(page.extract_text())\n",
    "    return \"\\n\".join(filter(None, full_text))\n",
    "\n",
    "# Test de unidad básico\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"./test_docs/manual_empleado.pdf\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    print(f\"Extracted text length: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83e77a",
   "metadata": {},
   "source": [
    "## 2. Text Splitting into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8f501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created: 282\n",
      "First chunk preview: 13. Uso de Sistemas Computarizados  ......................................................................................  15\n",
      "\t 14.\t Confidencialidad\tde\tInformación\t  .......................................................................................  19\n",
      "\t 15.\t Conflicto\tde\tInterés\t  ............................................................................................................  19TABLA DE CONTENIDO\n",
      "II.  LICENCIAS\n",
      " 1. Maternidad  .........................................................................................................................  20\n",
      " 2. Paternidad  ...........................................................................................................................  21\n",
      " 3. Servicio Militar  ..................................................................................................................  21\n"
     ]
    }
   ],
   "source": [
    "# chunking.py\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 100) -> List[str]:\n",
    "    \"\"\"\n",
    "    Divide el texto en chunks compatibles con LangChain.\n",
    "    \n",
    "    Args:\n",
    "      text (str): Texto completo a dividir.\n",
    "      chunk_size (int): Tamaño máximo por chunk.\n",
    "      chunk_overlap (int): Tamaño de overlap para mantener contexto.\n",
    "      \n",
    "    Returns:\n",
    "      List[str]: Lista de fragmentos de texto.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# Test unidad básico\n",
    "if __name__ == \"__main__\":\n",
    "    chunks = chunk_text(text)\n",
    "    print(f\"Chunks created: {len(chunks)}\")\n",
    "    print(f\"First chunk preview: {chunks[0][:2000]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06e27f",
   "metadata": {},
   "source": [
    "## 3. Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00fa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cn/lj16zlj56_v83zrg9_b4r9gr0000gn/T/ipykernel_33435/3066673761.py:37: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model': 'text-embedding...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Test básico\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     embeddings = \u001b[43mcreate_openai_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding vector length for first text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mcreate_openai_embeddings\u001b[39m\u001b[34m(texts)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03mCrea embeddings usando el modelo text-embedding-3-small de OpenAI, respetando el límite de tokens por solicitud.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m \u001b[33;03m  list[list[float]]: Vectores embedding.\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m embedding_model = \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-embedding-3-small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m batches = batch_texts_by_token_limit(texts)\n\u001b[32m     39\u001b[39m vectors = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages/langchain_core/_api/deprecation.py:226\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    225\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model': 'text-embedding...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "# embeddings.py\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import tiktoken\n",
    "from torch import chunk\n",
    "\n",
    "def batch_texts_by_token_limit(texts: list[str], max_tokens: int = 300000, model_name: str = \"text-embedding-3-small\") -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Divide la lista de textos en lotes para no exceder el límite de tokens por solicitud.\n",
    "    \"\"\"\n",
    "    enc = tiktoken.encoding_for_model(model_name)\n",
    "    batches = []\n",
    "    current_batch = []\n",
    "    current_tokens = 0\n",
    "    for text in texts:\n",
    "        tokens = len(enc.encode(text))\n",
    "        if current_tokens + tokens > max_tokens and current_batch:\n",
    "            batches.append(current_batch)\n",
    "            current_batch = []\n",
    "            current_tokens = 0\n",
    "        current_batch.append(text)\n",
    "        current_tokens += tokens\n",
    "    if current_batch:\n",
    "        batches.append(current_batch)\n",
    "    return batches\n",
    "\n",
    "def create_openai_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Crea embeddings usando el modelo text-embedding-3-small de OpenAI, respetando el límite de tokens por solicitud.\n",
    "    Args:\n",
    "      texts (list[str]): Lista de textos a vectorizar.\n",
    "      openai_api_key (str): API Key OpenAI.\n",
    "    Returns:\n",
    "      list[list[float]]: Vectores embedding.\n",
    "    \"\"\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    batches = batch_texts_by_token_limit(texts)\n",
    "    vectors = []\n",
    "    for batch in batches:\n",
    "        vectors.extend(embedding_model.embed_documents(batch))\n",
    "    return vectors\n",
    "\n",
    "# Test básico\n",
    "if __name__ == \"__main__\":\n",
    "    embeddings = create_openai_embeddings(chunks)\n",
    "    print(f\"Embedding vector length for first text: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c82e20",
   "metadata": {},
   "source": [
    "## 4. Vector Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3d89880",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m batches = batch_texts_by_token_limit(chunks)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[43msave_embeddings_in_chromadb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./db\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEmbeddings guardados con éxito.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36msave_embeddings_in_chromadb\u001b[39m\u001b[34m(texts, metadatas, persist_directory)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_embeddings_in_chromadb\u001b[39m(\n\u001b[32m      9\u001b[39m     texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     10\u001b[39m     metadatas: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m],\n\u001b[32m     11\u001b[39m     persist_directory: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m     12\u001b[39m ):\n\u001b[32m     13\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m    Guarda fragmentos y embeddings en ChromaDB para búsqueda.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m \u001b[33;03m      openai_api_key (str): API Key OpenAI para crear embeddings.\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m     embedding_model = OpenAIEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     vectorstore = Chroma(\n\u001b[32m     25\u001b[39m         collection_name=\u001b[33m\"\u001b[39m\u001b[33minternal_docs\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m         embedding_function=embedding_model,\n\u001b[32m     27\u001b[39m         persist_directory=persist_directory\n\u001b[32m     28\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:721\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:795\u001b[39m, in \u001b[36mencode\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "# vector_store.py\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "def save_embeddings_in_chromadb(\n",
    "    texts: list[str],\n",
    "    metadatas: list[dict],\n",
    "    persist_directory: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Guarda fragmentos y embeddings en ChromaDB para búsqueda.\n",
    "    Args:\n",
    "      texts: Lista de documentos/textos.\n",
    "      metadatas: Lista de diccionarios con metadatos, mismo orden que texts.\n",
    "      persist_directory (str): Carpeta donde persistir la DB.\n",
    "      openai_api_key (str): API Key OpenAI para crear embeddings.\n",
    "    \"\"\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"internal_docs\",\n",
    "        embedding_function=embedding_model,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "    vectorstore.persist()\n",
    "    vectorstore = None  # Liberar memoria\n",
    "\n",
    "    # Test básico\n",
    "if __name__ == \"__main__\":\n",
    "    sample_metadata = [{\"source\": pdf_path}]\n",
    "\n",
    "    batches = batch_texts_by_token_limit(chunks)\n",
    "    for batch in batches:\n",
    "        save_embeddings_in_chromadb(batch, sample_metadata, \"./db\")\n",
    "    print(\"Embeddings guardados con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da1ee7",
   "metadata": {},
   "source": [
    "## 5. Retriving from the Persistant Vector Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd2322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesarvelazquez/Documents/Personal/CursoIA_Tec/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# retriever.py\n",
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from chromadb.config import Settings\n",
    "import chromadb\n",
    "\n",
    "def load_retriever(persist_directory: str, openai_api_key: str):\n",
    "    \"\"\"\n",
    "    Carga la base ChromaDB como vectorstore para realizar consultas.\n",
    "    Retorna el objeto retriever.\n",
    "    \"\"\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=\"internal_docs\",\n",
    "        embedding_function=embedding_model,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":4})\n",
    "    return retriever\n",
    "\n",
    "# Test básico: recuperar textos similares\n",
    "if __name__ == \"__main__\":\n",
    "    retriever = load_retriever(\"./db\", os.getenv(\"OPENAI_API_KEY\"))\n",
    "    query = \"¿Cuáles son las políticas de seguridad?\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    print(f\"Documentos recuperados: {len(docs)}\")\n",
    "    print(f\"Primera doc preview: {docs[0].page_content[:300] if docs else 'Sin resultados'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abf77e",
   "metadata": {},
   "source": [
    "## 6. Retrivers in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_answer.py\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "def generate_answer_from_rag(question: str, retriever, openai_api_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Dada una pregunta y un retriever, genera una respuesta usando RAG y modelo GPT.\n",
    "    \n",
    "    Args:\n",
    "      question (str): Pregunta a responder.\n",
    "      retriever: Retriever previamente inicializado (ChromaDB).\n",
    "      openai_api_key (str): API key para OpenAI.\n",
    "      \n",
    "    Returns:\n",
    "      str: Respuesta generada.\n",
    "    \"\"\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    result = qa_chain.run(question)\n",
    "    return result\n",
    "\n",
    "# Test básico\n",
    "if __name__ == \"__main__\":\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    retriever = load_retriever(\"./db\", openai_api_key)\n",
    "    question = \"¿Qué procedimientos debo seguir en caso de emergencia laboral?\"\n",
    "    answer = generate_answer_from_rag(question, retriever, openai_api_key)\n",
    "    print(f\"Respuesta:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b29c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_rag_system.py\n",
    "import pytest\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def setup_teardown():\n",
    "    \"\"\"\n",
    "    Fixture para preparar entorno con embedding y textos de ejemplo y limpiar después.\n",
    "    \"\"\"\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if openai_api_key is None:\n",
    "        pytest.skip(\"OPENAI_API_KEY no está configurado en el entorno de prueba.\")\n",
    "    \n",
    "    # Paso 1: Extraer texto dummy (se podría usar pdf real aquí)\n",
    "    sample_text = \"Las políticas de seguridad establecen que \" \\\n",
    "                  \"todo empleado debe reportar incidentes.\\n\" \\\n",
    "                  \"En caso de emergencia laboral, sigue el protocolo ABC.\\n\" \\\n",
    "                  \"El horario de trabajo es de 9 a 18 hrs con pausa para almuerzo.\\n\" \\\n",
    "                  \"Los reportes trimestrales están basados en indicadores XYZ.\\n\" \\\n",
    "                  \"Cualquier cambio en política debe ser aprobado por RRHH.\"\n",
    "    chunks = chunk_text(sample_text)\n",
    "    metadatas = [{\"source\": f\"chunk-{i}\"} for i in range(len(chunks))]\n",
    "    \n",
    "    persist_dir = \"./test_db\"\n",
    "    \n",
    "    # Guardar embeddings\n",
    "    save_embeddings_in_chromadb(chunks, metadatas, persist_dir, openai_api_key)\n",
    "    \n",
    "    yield openai_api_key, persist_dir\n",
    "    \n",
    "    # Cleanup\n",
    "    if os.path.exists(persist_dir):\n",
    "        shutil.rmtree(persist_dir)\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"question\", [\n",
    "    \"¿Cuáles son las políticas de seguridad?\",\n",
    "    \"¿Qué hacer en caso de emergencia laboral?\",\n",
    "    \"¿Cuál es el horario de trabajo?\",\n",
    "    \"¿En qué se basan los reportes trimestrales?\",\n",
    "    \"¿Quién aprueba los cambios en las políticas?\"\n",
    "])\n",
    "def test_rag_answers(setup_teardown, question):\n",
    "    openai_api_key, persist_dir = setup_teardown\n",
    "    retriever = load_retriever(persist_dir, openai_api_key)\n",
    "    answer = generate_answer_from_rag(question, retriever, openai_api_key)\n",
    "    \n",
    "    assert isinstance(answer, str)\n",
    "    assert len(answer.strip()) > 0\n",
    "    # Extra simple: la respuesta debe tener al menos 10 caracteres.\n",
    "    assert len(answer) > 10\n",
    "\n",
    "\n",
    "# Seguridad básica: test contra inyección SQL simulada (en este contexto vectors, es más prevención de inputs malignos)\n",
    "def test_sql_injection_prevention(setup_teardown):\n",
    "    openai_api_key, persist_dir = setup_teardown\n",
    "    retriever = load_retriever(persist_dir, openai_api_key)\n",
    "    injection_string = \"'; DROP TABLE users; --\"\n",
    "    answer = generate_answer_from_rag(injection_string, retriever, openai_api_key)\n",
    "    # Validamos que el código no explota y responde algo\n",
    "    assert answer is not None\n",
    "\n",
    "\n",
    "# Contract test: Validar esquema Response OpenAPI simple (mock de esquema)\n",
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "class OpenAPIResponseSchema(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "def test_openapi_contract(setup_teardown):\n",
    "    openai_api_key, persist_dir = setup_teardown\n",
    "    retriever = load_retriever(persist_dir, openai_api_key)\n",
    "    question = \"¿Cuál es el protocolo de emergencias?\"\n",
    "    answer = generate_answer_from_rag(question, retriever, openai_api_key)\n",
    "    try:\n",
    "        # Simular que la respuesta viene en formato JSON { \"answer\": <respuesta> }\n",
    "        data = {\"answer\": answer}\n",
    "        validated = OpenAPIResponseSchema(**data)\n",
    "        assert validated.answer == answer\n",
    "    except ValidationError:\n",
    "        pytest.fail(\"Respuesta no cumple esquema OpenAPI esperado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
